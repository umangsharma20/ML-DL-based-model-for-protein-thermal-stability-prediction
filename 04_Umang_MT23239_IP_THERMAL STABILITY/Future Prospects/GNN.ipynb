{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu3EA8yveg83",
        "outputId": "d77ce1eb-aa30-4d1e-d2d5-7656d78ce0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting biopandas\n",
            "  Downloading biopandas-0.4.1-py2.py3-none-any.whl (878 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spektral) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from spektral) (4.9.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from spektral) (3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from spektral) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spektral) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spektral) (4.66.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2024.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spektral) (3.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: biopython, biopandas, spektral\n",
            "Successfully installed biopandas-0.4.1 biopython-1.83 spektral-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas keras tensorflow biopython biopandas matplotlib spektral\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from biopandas.pdb import PandasPdb\n",
        "from scipy.sparse import csr_matrix\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = 'PDB str-20240520T081153Z-001.zip'  # Replace with the actual path of the uploaded zip file\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extraction_path = 'extracted_folder'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Example property dictionary (values are illustrative)\n",
        "atom_properties = {\n",
        "    'H': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    'C': [0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "    'N': [0.3, 0.4, 0.5, 0.6, 0.7],\n",
        "    'O': [0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'S': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    # Add more atom types and their properties as needed\n",
        "}\n",
        "\n",
        "def preprocess_pdb_to_graph(pdb_file):\n",
        "    ppdb = PandasPdb().read_pdb(pdb_file)\n",
        "    atoms = ppdb.df['ATOM']\n",
        "\n",
        "    coords = atoms[['x_coord', 'y_coord', 'z_coord']].values\n",
        "    atom_types = atoms['element_symbol'].values\n",
        "\n",
        "    # Generate node features with additional properties\n",
        "    node_features = []\n",
        "    for atom in atom_types:\n",
        "        properties = atom_properties.get(atom, [0, 0, 0, 0, 0])  # Default properties if atom not in dictionary\n",
        "        node_features.append(properties)\n",
        "    node_features = np.array(node_features)\n",
        "\n",
        "    # Create edges based on distance\n",
        "    from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "    dist_matrix = squareform(pdist(coords))\n",
        "    threshold = 4.0  # Threshold for considering an edge\n",
        "    adj_matrix = (dist_matrix < threshold).astype(np.float32)\n",
        "    np.fill_diagonal(adj_matrix, 0)  # Remove self-loops\n",
        "\n",
        "    return {'node_features': node_features, 'adj_matrix': adj_matrix}\n",
        "\n",
        "# Test the extraction and preprocessing\n",
        "extracted_files = os.listdir(extraction_path)\n",
        "print(f'Extracted files: {extracted_files}')\n",
        "\n",
        "# Look inside the 'PDB str' directory\n",
        "pdb_dir = os.path.join(extraction_path, 'PDB str')\n",
        "pdb_files = [f for f in os.listdir(pdb_dir) if f.endswith('.pdb')]\n",
        "print(f'PDB files: {pdb_files}')\n",
        "\n",
        "if pdb_files:\n",
        "    pdb_file = os.path.join(pdb_dir, pdb_files[0])\n",
        "    graph = preprocess_pdb_to_graph(pdb_file)\n",
        "    print(f'Graph node features:\\n{graph[\"node_features\"]}')\n",
        "    print(f'Graph adjacency matrix:\\n{graph[\"adj_matrix\"]}')\n",
        "else:\n",
        "    print('No PDB files found in the \"PDB str\" directory.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d65kZmBdR29e",
        "outputId": "63773b03-a6cc-4faa-a4d2-9b01e31488c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['PDB str']\n",
            "PDB files: ['AF-Q8GR83-F1-model_v4.pdb', 'AF-P63000-F1-model_v4.pdb', 'AF-Q8BIQ5-F1-model_v4.pdb', 'AF-P0A6J3-F1-model_v4.pdb', 'AF-Q6L209-F1-model_v4.pdb', 'AF-Q72LL1-F1-model_v4.pdb', 'AF-P43609-F1-model_v4.pdb', 'AF-Q5SK53-F1-model_v4.pdb', 'AF-Q72JG7-F1-model_v4.pdb', 'AF-O05519-F1-model_v4.pdb', 'AF-Q72LB1-F1-model_v4.pdb', 'AF-Q6L1A4-F1-model_v4.pdb', 'AF-Q9LUH8-F1-model_v4.pdb', 'AF-O87197-F1-model_v4.pdb', 'AF-Q5SJG0-F1-model_v4.pdb', 'AF-Q3UBY5-F1-model_v4.pdb', 'AF-Q72JU8-F1-model_v4.pdb', 'AF-G5EG62-F1-model_v4.pdb', 'AF-Q3TJ39-F1-model_v4.pdb', 'AF-Q6L0H3-F1-model_v4.pdb', 'AF-Q9D938-F1-model_v4.pdb', 'AF-Q6KZ44-F1-model_v4.pdb', 'AF-P0ACY3-F1-model_v4.pdb', 'AF-Q9H0K1-F1-model_v4.pdb', 'AF-Q72K70-F1-model_v4.pdb', 'AF-P56690-F1-model_v4.pdb', 'AF-P56194-F1-model_v4.pdb', 'AF-Q8W4I9-F1-model_v4.pdb', 'AF-Q8N8S7-F1-model_v4.pdb', 'AF-Q5SJN7-F1-model_v4.pdb', 'AF-O01963-F1-model_v4.pdb', 'AF-Q72HB6-F1-model_v4.pdb', 'AF-Q72IH8-F1-model_v4.pdb', 'AF-Q5SKV2-F1-model_v4.pdb', 'AF-Q72JL7-F1-model_v4.pdb', 'AF-Q19731-F1-model_v4.pdb', 'AF-Q6A3Q2-F1-model_v4.pdb', 'AF-Q5SM00-F1-model_v4.pdb', 'AF-Q6L1R4-F1-model_v4.pdb', 'AF-Q9D6K9-F1-model_v4.pdb', 'AF-Q72IA9-F1-model_v4.pdb', 'AF-D6RDJ1-F1-model_v4.pdb', 'AF-P0AEZ9-F1-model_v4.pdb', 'AF-Q72GA6-F1-model_v4.pdb', 'AF-G3V5V7-F1-model_v4.pdb', 'AF-P51148-F1-model_v4.pdb', 'AF-Q746M9-F1-model_v4.pdb', 'AF-Q21902-F1-model_v4.pdb', 'AF-P0A817-F1-model_v4.pdb', 'AF-Q6L2I3-F1-model_v4.pdb', 'AF-Q5SLE0-F1-model_v4.pdb', 'AF-O80885-F1-model_v4.pdb', 'AF-Q5SHN3-F1-model_v4.pdb', 'AF-Q5DX36-F1-model_v4.pdb', 'AF-Q53WD8-F1-model_v4.pdb', 'AF-Q53VV1-F1-model_v4.pdb', 'AF-D1MN85-F1-model_v4.pdb', 'AF-P45880-F1-model_v4.pdb', 'AF-Q9FWA3-F1-model_v4.pdb', 'AF-Q9U287-F1-model_v4.pdb', 'AF-K7ENR6-F1-model_v4.pdb', 'AF-Q72KJ6-F1-model_v4.pdb', 'AF-Q8BHC7-F1-model_v4.pdb', 'AF-P42844-F1-model_v4.pdb', 'AF-P91875-F1-model_v4.pdb', 'AF-P33920-F1-model_v4.pdb', 'AF-P0AFW8-F1-model_v4.pdb', 'AF-Q05825-F1-model_v4.pdb', 'AF-D9UBX6-F1-model_v4.pdb', 'AF-Q72L90-F1-model_v4.pdb', 'AF-Q72KN7-F1-model_v4.pdb', 'AF-Q72KE1-F1-model_v4.pdb', 'AF-Q5TZA2-F1-model_v4.pdb', 'AF-Q6KZT9-F1-model_v4.pdb', 'AF-P22033-F1-model_v4.pdb', 'AF-Q94361-F1-model_v4.pdb', 'AF-Q72LF8-F1-model_v4.pdb', 'AF-R4YLL3-F1-model_v4.pdb', 'AF-Q9GYP1-F1-model_v4.pdb', 'AF-A9Z1L6-F1-model_v4.pdb', 'AF-Q72IP2-F1-model_v4.pdb', 'AF-P05379-F1-model_v4.pdb', 'AF-Q5SHU1-F1-model_v4.pdb', 'AF-P53999-F1-model_v4.pdb', 'AF-Q56425-F1-model_v4.pdb', 'AF-P06168-F1-model_v4.pdb', 'AF-Q72GA4-F1-model_v4.pdb', 'AF-R4YQB9-F1-model_v4.pdb', 'AF-Q6L2M4-F1-model_v4.pdb', 'AF-P0A8A0-F1-model_v4.pdb', 'AF-P0A6Y1-F1-model_v4.pdb', 'AF-Q72HU2-F1-model_v4.pdb', 'AF-Q6L2V6-F1-model_v4.pdb', 'AF-R4YPU7-F1-model_v4.pdb', 'AF-Q6NZB1-F1-model_v4.pdb', 'AF-R4YL90-F1-model_v4.pdb', 'AF-Q6L079-F1-model_v4.pdb', 'AF-Q15788-F1-model_v4.pdb', 'AF-Q9Y2I8-F1-model_v4.pdb', 'AF-Q18142-F1-model_v4.pdb', 'AF-P27000-F1-model_v4.pdb', 'AF-Q72LH3-F1-model_v4.pdb', 'AF-Q03012-F1-model_v4.pdb', 'AF-O76561-F1-model_v4.pdb', 'AF-O45686-F1-model_v4.pdb', 'AF-P09622-F1-model_v4.pdb', 'AF-Q6L0B8-F1-model_v4.pdb', 'AF-Q746P6-F1-model_v4.pdb', 'AF-Q6KZP1-F1-model_v4.pdb', 'AF-Q90ZC5-F1-model_v4.pdb', 'AF-Q15019-F1-model_v4.pdb', 'AF-Q8VRL7-F1-model_v4.pdb', 'AF-Q746N7-F1-model_v4.pdb', 'AF-Q19371-F1-model_v4.pdb', 'AF-Q19230-F1-model_v4.pdb', 'AF-G5EE66-F1-model_v4.pdb', 'AF-P0A9F3-F1-model_v4.pdb', 'AF-P0AAN3-F1-model_v4.pdb', 'AF-Q22875-F1-model_v4.pdb', 'AF-Q72K86-F1-model_v4.pdb', 'AF-Q4KMD0-F1-model_v4.pdb', 'AF-P0A8F0-F1-model_v4.pdb', 'AF-Q72IV2-F1-model_v4.pdb', 'AF-O31634-F1-model_v4.pdb', 'AF-Q72HD8-F1-model_v4.pdb', 'AF-Q6L1D6-F1-model_v4.pdb', 'AF-Q9S7H1-F1-model_v4.pdb', 'AF-Q5SM34-F1-model_v4.pdb', 'AF-P10795-F1-model_v4.pdb', 'AF-K8ESG0-F1-model_v4.pdb', 'AF-Q5SJQ7-F1-model_v4.pdb', 'AF-Q8R0J4-F1-model_v4.pdb', 'AF-Q72HI6-F1-model_v4.pdb', 'AF-Q6KZT5-F1-model_v4.pdb', 'AF-P14174-F1-model_v4.pdb', 'AF-Q6KYX9-F1-model_v4.pdb', 'AF-Q18739-F1-model_v4.pdb', 'AF-G3X983-F1-model_v4.pdb', 'AF-Q72GM4-F1-model_v4.pdb', 'AF-Q5SJ47-F1-model_v4.pdb', 'AF-O04316-F1-model_v4.pdb', 'AF-E7EUI8-F1-model_v4.pdb', 'AF-Q9VP05-F1-model_v4.pdb', 'AF-Q5SLK3-F1-model_v4.pdb', 'AF-Q72LA0-F1-model_v4.pdb', 'AF-J3QTM1-F1-model_v4.pdb', 'AF-Q72I01-F1-model_v4.pdb', 'AF-Q746H3-F1-model_v4.pdb', 'AF-P62141-F1-model_v4.pdb', 'AF-Q746D7-F1-model_v4.pdb', 'AF-Q5SMD7-F1-model_v4.pdb', 'AF-P0A6Q3-F1-model_v4.pdb', 'AF-P75691-F1-model_v4.pdb', 'AF-P0ACR9-F1-model_v4.pdb', 'AF-Q9GYM9-F1-model_v4.pdb', 'AF-Q72IC8-F1-model_v4.pdb', 'AF-Q5SL21-F1-model_v4.pdb', 'AF-Q72IA8-F1-model_v4.pdb', 'AF-Q5SJF2-F1-model_v4.pdb', 'AF-G5EFM9-F1-model_v4.pdb', 'AF-Q6PFT1-F1-model_v4.pdb', 'AF-Q72KR9-F1-model_v4.pdb', 'AF-Q9CQF6-F1-model_v4.pdb', 'AF-Q53W40-F1-model_v4.pdb', 'AF-P69411-F1-model_v4.pdb', 'AF-Q6L1T2-F1-model_v4.pdb', 'AF-Q5SH77-F1-model_v4.pdb', 'AF-B1AJY7-F1-model_v4.pdb', 'AF-Q6AXL0-F1-model_v4.pdb', 'AF-O62214-F1-model_v4.pdb', 'AF-F1Q8A5-F1-model_v4.pdb', 'AF-Q72K33-F1-model_v4.pdb', 'AF-Q9BXJ9-F1-model_v4 (1).pdb', 'AF-Q9HD26-F1-model_v4.pdb', 'AF-Q7L0Y3-F1-model_v4.pdb', 'AF-Q61753-F1-model_v4.pdb', 'AF-Q72G96-F1-model_v4.pdb', 'AF-Q9FKA0-F1-model_v4.pdb', 'AF-Q746H8-F1-model_v4.pdb', 'AF-Q72JN9-F1-model_v4.pdb', 'AF-Q5SHF6-F1-model_v4.pdb', 'AF-Q72L56-F1-model_v4.pdb', 'AF-Q72J16-F1-model_v4.pdb', 'AF-P05652-F1-model_v4.pdb', 'AF-Q6L254-F1-model_v4.pdb', 'AF-P34630-F1-model_v4.pdb', 'AF-Q72KX0-F1-model_v4.pdb', 'AF-Q72IX8-F1-model_v4.pdb', 'AF-P10586-F1-model_v4.pdb', 'AF-Q9H8H0-F1-model_v4.pdb', 'AF-A0A0R4J0D3-F1-model_v4.pdb', 'AF-Q9VB25-F1-model_v4.pdb', 'AF-Q6L2V9-F1-model_v4.pdb', 'AF-Q5SHQ7-F1-model_v4.pdb', 'AF-Q72GD3-F1-model_v4.pdb', 'AF-Q9VUX2-F1-model_v4.pdb', 'AF-Q5SH83-F1-model_v4.pdb', 'AF-Q5SHH9-F1-model_v4.pdb', 'AF-P49954-F1-model_v4.pdb', 'AF-Q9LYB4-F1-model_v4.pdb', 'AF-Q9VDD7-F1-model_v4.pdb', 'AF-P42620-F1-model_v4.pdb', 'AF-A8MYC1-F1-model_v4.pdb', 'AF-P32177-F1-model_v4.pdb', 'AF-R4YM74-F1-model_v4.pdb', 'AF-Q21215-F1-model_v4.pdb', 'AF-Q9VPD5-F1-model_v4.pdb', 'AF-Q72JG4-F1-model_v4.pdb', 'AF-Q72HA4-F1-model_v4.pdb', 'AF-Q9U1Q4-F1-model_v4.pdb', 'AF-Q6IMW9-F1-model_v4.pdb', 'AF-O49299-F1-model_v4.pdb', 'AF-Q5SKY3-F1-model_v4.pdb', 'AF-Q72HA7-F1-model_v4.pdb', 'AF-Q5SIV7-F1-model_v4.pdb', 'AF-Q9JJR8-F1-model_v4.pdb', 'AF-P62453-F1-model_v4.pdb', 'AF-Q07868-F1-model_v4.pdb', 'AF-Q72HU7-F1-model_v4.pdb', 'AF-Q9VXK6-F1-model_v4.pdb', 'AF-F6TFF2-F1-model_v4.pdb', 'AF-Q72IC7-F1-model_v4.pdb', 'AF-Q9Y6J9-F1-model_v4.pdb', 'AF-Q72JY2-F1-model_v4.pdb', 'AF-P11717-F1-model_v4.pdb', 'AF-P35813-F1-model_v4.pdb', 'AF-Q5SHY5-F1-model_v4.pdb', 'AF-Q6L0F9-F1-model_v4.pdb', 'AF-Q6KZL8-F1-model_v4.pdb', 'AF-R4YMA4-F1-model_v4.pdb', 'AF-Q18990-F1-model_v4.pdb', 'AF-Q6XZF7-F1-model_v4.pdb', 'AF-O01905-F1-model_v4.pdb', 'AF-Q8BYB9-F1-model_v4.pdb', 'AF-Q6KZU1-F1-model_v4.pdb', 'AF-R4YMB5-F1-model_v4.pdb', 'AF-Q9UNN8-F1-model_v4.pdb', 'AF-Q8VHN8-F1-model_v4.pdb', 'AF-R4YKD1-F1-model_v4.pdb', 'AF-Q9BRX9-F1-model_v4.pdb', 'AF-Q5SIW2-F1-model_v4.pdb', 'AF-Q72LC9-F1-model_v4.pdb', 'AF-Q5SKC4-F1-model_v4.pdb', 'AF-Q72HX7-F1-model_v4.pdb', 'AF-Q5SJY7-F1-model_v4.pdb', 'AF-Q72JS8-F1-model_v4.pdb', 'AF-Q60FD1-F1-model_v4.pdb', 'AF-Q9D162-F1-model_v4.pdb', 'AF-O94906-F1-model_v4.pdb', 'AF-Q72KR3-F1-model_v4.pdb', 'AF-Q6L164-F1-model_v4.pdb', 'AF-Q5SKR7-F1-model_v4.pdb', 'AF-O16297-F1-model_v4.pdb', 'AF-P23686-F1-model_v4.pdb', 'AF-O77263-F1-model_v4.pdb', 'AF-Q6L0V3-F1-model_v4.pdb', 'AF-Q72H85-F1-model_v4.pdb', 'AF-Q72I74-F1-model_v4.pdb', 'AF-Q6L0B7-F1-model_v4.pdb', 'AF-Q72KW3-F1-model_v4.pdb', 'AF-Q544Q7-F1-model_v4.pdb', 'AF-Q8WTM6-F1-model_v4.pdb', 'AF-Q5T160-F1-model_v4.pdb', 'AF-G5ECR1-F1-model_v4.pdb', 'AF-P40693-F1-model_v4.pdb', 'AF-Q72KB8-F1-model_v4.pdb', 'AF-Q9BYM8-F1-model_v4.pdb', 'AF-P37626-F1-model_v4.pdb', 'AF-P32748-F1-model_v4.pdb', 'AF-Q72HM6-F1-model_v4.pdb', 'AF-Q72HT7-F1-model_v4.pdb', 'AF-Q8LB17-F1-model_v4.pdb', 'AF-Q72KB2-F1-model_v4.pdb', 'AF-Q72JB4-F1-model_v4.pdb', 'AF-P39958-F1-model_v4.pdb', 'AF-Q6L021-F1-model_v4.pdb', 'AF-Q5SI61-F1-model_v4.pdb', 'AF-Q5SM81-F1-model_v4.pdb', 'AF-P07259-F1-model_v4.pdb', 'AF-Q72JR6-F1-model_v4.pdb', 'AF-Q56403-F1-model_v4.pdb', 'AF-Q86D20-F1-model_v4.pdb', 'AF-Q72IV4-F1-model_v4.pdb', 'AF-Q5SLR3-F1-model_v4.pdb', 'AF-Q5SLX5-F1-model_v4.pdb', 'AF-P76291-F1-model_v4.pdb', 'AF-Q72LJ6-F1-model_v4.pdb', 'AF-Q9VH39-F1-model_v4.pdb', 'AF-Q6L0Y7-F1-model_v4.pdb', 'AF-Q6L1H1-F1-model_v4.pdb', 'AF-Q72GK7-F1-model_v4.pdb', 'AF-P14081-F1-model_v4.pdb', 'AF-Q5SIT2-F1-model_v4.pdb', 'AF-Q72J93-F1-model_v4.pdb', 'AF-Q53VU6-F1-model_v4.pdb', 'AF-O97067-F1-model_v4.pdb', 'AF-Q6L1J7-F1-model_v4.pdb', 'AF-Q5SH14-F1-model_v4.pdb', 'AF-Q6L2E2-F1-model_v4.pdb', 'AF-Q53WF6-F1-model_v4.pdb', 'AF-Q72I62-F1-model_v4.pdb', 'AF-Q5SK84-F1-model_v4.pdb', 'AF-Q72IE0-F1-model_v4.pdb', 'AF-Q5SM60-F1-model_v4.pdb', 'AF-P65292-F1-model_v4.pdb', 'AF-Q72GR3-F1-model_v4.pdb', 'AF-P46459-F1-model_v4.pdb', 'AF-Q9NVR0-F1-model_v4.pdb', 'AF-Q72IP9-F1-model_v4.pdb', 'AF-O14744-F1-model_v4.pdb', 'AF-Q9F0S9-F1-model_v4.pdb', 'AF-Q6L270-F1-model_v4.pdb', 'AF-Q6L1B4-F1-model_v4.pdb', 'AF-Q5SJ30-F1-model_v4.pdb', 'AF-Q84B23-F1-model_v4.pdb', 'AF-Q9H2M9-F1-model_v4.pdb', 'AF-B9EKL6-F1-model_v4.pdb', 'AF-Q9NEI6-F1-model_v4.pdb', 'AF-Q72GU1-F1-model_v4.pdb', 'AF-Q9VVU5-F1-model_v4.pdb', 'AF-P34580-F1-model_v4.pdb', 'AF-H2KZY3-F1-model_v4.pdb', 'AF-Q9BXJ9-F1-model_v4.pdb', 'AF-P34678-F1-model_v4.pdb', 'AF-Q72IB8-F1-model_v4.pdb', 'AF-Q5SLF5-F1-model_v4.pdb', 'AF-P0AG51-F1-model_v4.pdb', 'AF-P40818-F1-model_v4.pdb', 'AF-R4YP97-F1-model_v4.pdb', 'AF-Q6L1K5-F1-model_v4.pdb', 'AF-Q6L0D1-F1-model_v4.pdb', 'AF-O16486-F1-model_v4.pdb', 'AF-Q95Y73-F1-model_v4.pdb', 'AF-Q72K32-F1-model_v4.pdb', 'AF-Q5SSH8-F1-model_v4.pdb', 'AF-Q9VD26-F1-model_v4.pdb', 'AF-R4YPW6-F1-model_v4.pdb', 'AF-P53043-F1-model_v4.pdb', 'AF-P29513-F1-model_v4.pdb', 'AF-R4YUN3-F1-model_v4.pdb', 'AF-Q5SLC3-F1-model_v4.pdb', 'AF-Q6L131-F1-model_v4.pdb', 'AF-Q745X5-F1-model_v4.pdb', 'AF-R4YLB4-F1-model_v4.pdb', 'AF-P61989-F1-model_v4.pdb', 'AF-Q5SLZ5-F1-model_v4.pdb', 'AF-Q5SJG8-F1-model_v4.pdb', 'AF-Q6L1C2-F1-model_v4.pdb', 'AF-E9PZF0-F1-model_v4.pdb']\n",
            "Graph node features:\n",
            "[[0.3 0.4 0.5 0.6 0.7]\n",
            " [0.2 0.3 0.4 0.5 0.6]\n",
            " [0.2 0.3 0.4 0.5 0.6]\n",
            " ...\n",
            " [0.4 0.5 0.6 0.7 0.8]\n",
            " [0.2 0.3 0.4 0.5 0.6]\n",
            " [0.4 0.5 0.6 0.7 0.8]]\n",
            "Graph adjacency matrix:\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [1. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN"
      ],
      "metadata": {
        "id": "4stmYcYLnGXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython numpy networkx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtJp9dAcSUK2",
        "outputId": "e4a98f80-5e47-4634-f514-f153c8b1e1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.83)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkiZGTT8MHuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = '/content/PDB str-20240520T081153Z-001.zip'  # Replace with the actual path of the uploaded zip file\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extraction_path = '/content/extracted_folder'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)"
      ],
      "metadata": {
        "id": "ZKowvVCHnNPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch if not already installed\n",
        "!pip install torch\n",
        "\n",
        "# Install torch_scatter, torch_sparse, torch_cluster, and torch_spline_conv\n",
        "# Find the correct versions for your PyTorch version at https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n",
        "\n",
        "# Install torch-geometric\n",
        "!pip install torch-geometric\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBv7dK71au0X",
        "outputId": "b8365c68-c53c-45d1-ea3e-7cc89fff75c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt23cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from Bio.PDB import PDBParser\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "\n",
        "# Mapping from element symbols to atomic numbers\n",
        "element_to_atomic_number = {\n",
        "    'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10,\n",
        "    'Na': 11, 'Mg': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20,\n",
        "    # Include all elements as needed\n",
        "}\n",
        "\n",
        "def parse_pdb(file_path):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('protein', file_path)\n",
        "    return structure\n",
        "\n",
        "def get_atom_features(atom):\n",
        "    atomic_number = element_to_atomic_number.get(atom.element, 0)\n",
        "    x, y, z = atom.coord\n",
        "    return [atomic_number, x, y, z]\n",
        "\n",
        "def create_graph_from_structure(structure):\n",
        "    graph = nx.Graph()\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                for atom in residue:\n",
        "                    atom_id = atom.get_serial_number()\n",
        "                    features = get_atom_features(atom)\n",
        "                    graph.add_node(atom_id, features=features)\n",
        "\n",
        "                    for other_atom in residue.get_atoms():\n",
        "                        if atom != other_atom:\n",
        "                            distance = atom - other_atom\n",
        "                            if distance < 4.0:\n",
        "                                other_atom_id = other_atom.get_serial_number()\n",
        "                                graph.add_edge(atom_id, other_atom_id, weight=distance)\n",
        "    return graph\n",
        "\n",
        "def preprocess_pdb_files(pdb_files):\n",
        "    graphs = []\n",
        "    all_features = []\n",
        "\n",
        "    for pdb_file in pdb_files:\n",
        "        structure = parse_pdb(pdb_file)\n",
        "        graph = create_graph_from_structure(structure)\n",
        "        graphs.append(graph)\n",
        "\n",
        "        for _, data in graph.nodes(data=True):\n",
        "            all_features.append(data['features'])\n",
        "\n",
        "    all_features = np.array(all_features)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(all_features)\n",
        "\n",
        "    for graph in graphs:\n",
        "        for node in graph.nodes:\n",
        "            graph.nodes[node]['features'] = scaler.transform([graph.nodes[node]['features']])[0]\n",
        "\n",
        "    return graphs\n",
        "\n",
        "def networkx_to_pyg(graph):\n",
        "    # Extract node features into a tensor\n",
        "    node_features = np.array([graph.nodes[n]['features'] for n in graph.nodes])\n",
        "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
        "\n",
        "    # Extract edge indices\n",
        "    edge_index = np.array(list(graph.edges)).T\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "    return Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "# Directory containing PDB files\n",
        "pdb_directory = '/content/extracted_folder/PDB str'\n",
        "pdb_files = [os.path.join(pdb_directory, file) for file in os.listdir(pdb_directory) if file.endswith('.pdb')]\n",
        "\n",
        "# Preprocess PDB files\n",
        "graphs = preprocess_pdb_files(pdb_files)\n",
        "\n",
        "# Convert NetworkX graphs to PyTorch Geometric Data objects\n",
        "pyg_graphs = [networkx_to_pyg(graph) for graph in graphs]\n",
        "\n",
        "# Example: Accessing node features and edge index for the first graph\n",
        "data = pyg_graphs[0]\n",
        "\n",
        "# PyTorch Geometric stores node features in `x` and edge indices in `edge_index`\n",
        "node_features = data.x\n",
        "edge_index = data.edge_index\n",
        "\n",
        "print(\"Node features:\\n\", node_features)\n",
        "print(\"Edge index:\\n\", edge_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_1sn1YWbAyR",
        "outputId": "73ff3ae7-1cc9-4854-97ca-a98d438b32e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features:\n",
            " tensor([[ 0.4046, -0.8463,  0.2758, -1.3642],\n",
            "        [-0.5909, -0.7909,  0.2633, -1.3984],\n",
            "        [-0.5909, -0.7519,  0.2010, -1.3691],\n",
            "        ...,\n",
            "        [-0.5909, -0.3513,  1.7452, -0.2062],\n",
            "        [ 0.4046, -0.3361,  1.8026, -0.1721],\n",
            "        [ 0.4046, -0.3895,  1.6903, -0.1893]])\n",
            "Edge index:\n",
            " tensor([[   1,    1,    1,  ..., 4210, 4210, 4208],\n",
            "        [   2,    3,    4,  ..., 4208, 4209, 4209]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "\n",
        "class CustomDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(CustomDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        # Load your preprocessed data here\n",
        "        pyg_graphs = []  # List of Data objects\n",
        "        # Add your pyg_graphs to the list\n",
        "        data, slices = self.collate(pyg_graphs)\n",
        "        return data, slices\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data.y)\n",
        "\n",
        "    def get(self, idx):\n",
        "        return self.data.__getitem__(idx)\n"
      ],
      "metadata": {
        "id": "OIOF7rU6isEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GNNModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "ERJkgUICiulo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "\n",
        "class CustomDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(CustomDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = self.process()\n",
        "\n",
        "    def process(self):\n",
        "        # Load and process your preprocessed data here\n",
        "        pyg_graphs = []  # List of Data objects\n",
        "        # Populate pyg_graphs with your preprocessed graphs\n",
        "\n",
        "        data_list = [self.data_to_pyg(graph) for graph in pyg_graphs]\n",
        "        return self.collate(data_list)\n",
        "\n",
        "    def data_to_pyg(self, graph):\n",
        "        # Convert a single graph (in whatever format you have) to PyTorch Geometric Data\n",
        "        # Example implementation:\n",
        "        node_features = graph.node_features  # Replace with actual data extraction method\n",
        "        edge_index = graph.edge_index  # Replace with actual data extraction method\n",
        "        # Assuming node_features and edge_index are tensors\n",
        "        return Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data.y)\n",
        "\n",
        "    def get(self, idx):\n",
        "        return self.data.__getitem__(idx)\n",
        "\n"
      ],
      "metadata": {
        "id": "wfxnyBWdix9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def compute_rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def compute_r2(y_true, y_pred):\n",
        "    return r2_score(y_true, y_pred)\n",
        "\n",
        "def compute_pearson(y_true, y_pred):\n",
        "    return pearsonr(y_true, y_pred)[0]  # Pearson returns a tuple, we need the coefficient only\n"
      ],
      "metadata": {
        "id": "uvyeADpDpLTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            output = model(batch)\n",
        "            y_true.extend(batch.y.cpu().numpy())\n",
        "            y_pred.extend(output.cpu().numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    rmse = compute_rmse(y_true, y_pred)\n",
        "    r2 = compute_r2(y_true, y_pred)\n",
        "    pearson = compute_pearson(y_true, y_pred)\n",
        "\n",
        "    return rmse, r2, pearson\n"
      ],
      "metadata": {
        "id": "Y_vWPJSMpPX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.PDB import PDBParser\n",
        "\n",
        "def parse_pdb(file_path):\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('structure', file_path)\n",
        "    atoms = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                for atom in residue:\n",
        "                    atoms.append(atom)\n",
        "    return atoms\n"
      ],
      "metadata": {
        "id": "XCtAfWskqldy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def create_graph(atoms):\n",
        "    G = nx.Graph()\n",
        "    for atom in atoms:\n",
        "        G.add_node(atom.serial_number, element=atom.element, coord=atom.coord)\n",
        "    # Add edges (bonds) based on distance criteria (e.g., covalent bonds)\n",
        "    for i, atom1 in enumerate(atoms):\n",
        "        for j, atom2 in enumerate(atoms):\n",
        "            if i < j:\n",
        "                distance = atom1 - atom2\n",
        "                if distance < 1.6:  # Example distance threshold for covalent bonds\n",
        "                    G.add_edge(atom1.serial_number, atom2.serial_number, weight=distance)\n",
        "    return G\n"
      ],
      "metadata": {
        "id": "7yhIzGpZqnDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def networkx_to_pyg(graph):\n",
        "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
        "    node_features = torch.tensor([list(graph.nodes[node]['coord']) for node in graph.nodes], dtype=torch.float)\n",
        "    return Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "# Process multiple PDB files\n",
        "def preprocess_pdb_files(pdb_files):\n",
        "    pyg_graphs = []\n",
        "    for file in pdb_files:\n",
        "        atoms = parse_pdb(file)\n",
        "        graph = create_graph(atoms)\n",
        "        pyg_graph = networkx_to_pyg(graph)\n",
        "        pyg_graphs.append(pyg_graph)\n",
        "    return pyg_graphs\n"
      ],
      "metadata": {
        "id": "fSKoIbTzqwf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from Bio.PDB import PDBParser\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Step 1: Parse PDB Files\n",
        "def parse_pdb(file_path):\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('structure', file_path)\n",
        "    atoms = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                for atom in residue:\n",
        "                    atoms.append(atom)\n",
        "    return atoms\n",
        "\n",
        "# Step 2: Create Graphs\n",
        "def create_graph(atoms):\n",
        "    G = nx.Graph()\n",
        "    for atom in atoms:\n",
        "        G.add_node(atom.serial_number, element=atom.element, coord=atom.coord)\n",
        "    for i, atom1 in enumerate(atoms):\n",
        "        for j, atom2 in enumerate(atoms):\n",
        "            if i < j:\n",
        "                distance = atom1 - atom2\n",
        "                if distance < 1.6:  # Example distance threshold for covalent bonds\n",
        "                    G.add_edge(atom1.serial_number, atom2.serial_number, weight=distance)\n",
        "    return G\n",
        "\n",
        "# Step 3: Convert to PyTorch Geometric Data Objects\n",
        "def networkx_to_pyg(graph):\n",
        "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
        "    node_features = torch.tensor([list(graph.nodes[node]['coord']) for node in graph.nodes], dtype=torch.float)\n",
        "    return Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "# Process multiple PDB files and include melting temperatures\n",
        "def preprocess_pdb_files(pdb_dir, csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    pyg_graphs = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        pdb_file = os.path.join(pdb_dir, row['pdb_file'])\n",
        "        melting_temp = row['melting_temp']\n",
        "        atoms = parse_pdb(pdb_file)\n",
        "        graph = create_graph(atoms)\n",
        "        pyg_graph = networkx_to_pyg(graph)\n",
        "        pyg_graph.y = torch.tensor([melting_temp], dtype=torch.float)  # Add target variable\n",
        "        pyg_graphs.append(pyg_graph)\n",
        "\n",
        "    return pyg_graphs\n",
        "\n",
        "# Directory and file paths\n",
        "pdb_dir = '/content/extracted_folder/PDB str'  # Folder containing all PDB files\n",
        "csv_file = '/content/PDB+TM - Sheet1 (1).csv'  # CSV file with PDB file names and melting temperatures\n",
        "\n",
        "# Preprocess the data\n",
        "pyg_graphs = preprocess_pdb_files(pdb_dir, csv_file)\n",
        "\n",
        "# Save preprocessed data\n",
        "processed_path = '/content/your_dataset/processed'\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "torch.save(pyg_graphs, f'{processed_path}/data.pt')\n",
        "\n",
        "# Step 5: Create a Custom Dataset\n",
        "class CustomDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(CustomDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []  # List of raw file names (if any)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        pass  # Download to `self.raw_dir`.\n",
        "\n",
        "    def process(self):\n",
        "        pass  # This method is called only if the processed data does not exist\n",
        "\n",
        "dataset_path = '/content/your_dataset'\n",
        "dataset = CustomDataset(root=dataset_path)\n",
        "\n",
        "# Step 6: Train Your GNN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset[0].num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, 1)  # For regression, use 1 output feature\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # Assuming regression problem\n",
        "\n",
        "model = GCN()\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for epoch in range(100):  # Number of epochs\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = loss_fn(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Optionally, evaluate on validation/test set\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    for data in train_loader:  # Change to validation_loader if you have one\n",
        "        with torch.no_grad():\n",
        "            out = model(data.x, data.edge_index)\n",
        "            preds.append(out.cpu().numpy())\n",
        "            targets.append(data.y.cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    r2 = r2_score(targets, preds)\n",
        "    pearson_corr, _ = pearsonr(targets.flatten(), preds.flatten())\n",
        "\n",
        "    print(f'Epoch: {epoch}, Loss: {loss.item()}, RMSE: {rmse}, R2: {r2}, Pearson: {pearson_corr}')\n",
        "\n",
        "# Save the trained model\n",
        "model_path = 'model.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f'Model saved to {model_path}')\n"
      ],
      "metadata": {
        "id": "lCghyg4esKYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}